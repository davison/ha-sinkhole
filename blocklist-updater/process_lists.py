#!/usr/bin/env python

import datetime
import re
import os
import urllib.request
import tempfile
from typing import List, Set

# The IP address to use in the output hosts file (0.0.0.0 is preferred for DNS sinkhole)
block_ip = "0.0.0.0"

# Regular expression compiled for faster matching.
# It handles both 'IP domain' (hosts file format) and 'domain' (plain list format).
domain_regex = re.compile(
    # Optional leading IP address (e.g., 0.0.0.0 or 127.0.0.1 followed by space)
    r'^(?:[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\s+)?'
    # Capture Group 1: The actual domain name (letters, numbers, hyphens, and dots)
    r'([a-zA-Z0-9\-\.]+)'
    # Non-capturing group: Trailing spaces, slashes, or comments (# or !)
    r'(?:[\s\/\#\!]?.*)?$'
)

# A set to store domains uniquely
unique_domains: Set[str] = set()

user_agent = 'HA-Sinkhole-Blocklist-Generator/1.0'

# --- Core Functions ---

def fetch_and_parse_list(url: str):
    """
    Fetches a blocklist from a URL, cleans each line, extracts the domain,
    and adds the domain to the global unique_domains set.
    """
    print(f"-> Processing list: {url}")
    try:
        # Create a Request object to set the User-Agent so the default Python agent is 
        # not treated badly by the server
        headers = {'User-Agent': user_agent}
        request = urllib.request.Request(url, headers=headers)

        # Use the request object with urlopen
        with urllib.request.urlopen(request, timeout=10) as response:
            for line_bytes in response:
                # Decode line and strip leading/trailing whitespace
                line = line_bytes.decode('utf-8', errors='ignore').strip()

                # Ignore comments and empty lines
                if not line or line.startswith(('#', '!', '/')):
                    continue

                match = domain_regex.match(line)
                if match:
                    domain = match.group(1).lower().strip('.') # 1. Strip trailing dots

                    # 2. Add stricter validation
                    if not domain: # Skip if domain was just '.'
                        continue

                    # 3. Check for invalid patterns
                    if ('..' in domain or 
                        domain.startswith('-') or 
                        domain.endswith('-') or 
                        domain == block_ip or
                        '.' not in domain):
                        continue

                    # 4. (Optional but recommended) Check each part (label)
                    if any(label.startswith('-') or label.endswith('-') for label in domain.split('.')):
                        continue

                    unique_domains.add(domain)

    except urllib.error.URLError as e:
        print(f"   [ERROR] Could not fetch {url}: {e.reason}")
    except Exception as e:
        print(f"   [ERROR] An unexpected error occurred while processing {url}: {e}")

def generate_hosts_file(output_path: str):
    """
    Writes the de-duplicated domains to a hosts file format.
    """
    domain_count = len(unique_domains)
    print(f"\n-> Writing {domain_count} unique domains to {output_path}...")

    temp_file_path = None
    try:
        # 1. Write to a NamedTemporaryFile
        # delete=False ensures the file is available for os.rename after the context manager closes.
        # dir=os.path.dirname(output_path) or '.' ensures the temp file is created in the same filesystem
        # to guarantee the atomic rename operation.
        with tempfile.NamedTemporaryFile(mode='w', delete=False, dir=os.path.dirname(output_path) or '.') as tmp_file:
            temp_file_path = tmp_file.name
            
            # Write a standard hosts file header
            timestamp = datetime.datetime.now(datetime.timezone.utc).isoformat()
            tmp_file.write(f"# Last updated (UTC): {timestamp}\n")
            tmp_file.write(f"# Generated by {user_agent}\n")
            tmp_file.write(f"# Total unique domains: {domain_count}\n\n")

            # Write each unique domain in hosts format, sorted alphabetically
            for domain in sorted(list(unique_domains)):
                tmp_file.write(f"{block_ip}\t{domain}\n")
        
        # 2. Atomically rename the temp file to the final output path
        os.rename(temp_file_path, output_path)
        print("-> Complete.")

    except Exception as e:
        print(f"   [ERROR] Failed to write or rename hosts file: {e}")
        # Clean up the temp file if the rename failed but the file still exists
        if temp_file_path and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

def main():
    """
    Main execution function.
    """
    # The default URL to use if the environment variable is missing or empty
    default_url = "https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts"
    
    blocklist_urls_env = os.environ.get('BLOCKLIST_URLS')    
    adlist_urls: List[str] = []

    if blocklist_urls_env:
        adlist_urls = blocklist_urls_env.split()

    if not adlist_urls:
        print(f"WARNING: BLOCKLIST_URLS not provided or was empty. Defaulting to: {default_url}")
        adlist_urls = [default_url]

    for url in adlist_urls:
        fetch_and_parse_list(url)
    
    generate_hosts_file("adlists.hosts")


if __name__ == "__main__":
    main()
